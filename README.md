# Gradient Descent algorithm

This code implements a Gradient Descent (GD) from scratch in order to minimize a loss function through a linear regression problem.
However, Gradient Descent can be employed in different ML algorithms and scenarios.

Basically, the optimizer is used in ML training step to find, as an optimization process, a set of weights and biases that have low loss, on average, across the entire training dataset.

To demonstrate the usage of the GD and its applicability to a linear regression problem, we are going to explore the dataset of Marketing and Sales from Kaggle, which contains information about TV, influencer, radio, and social media ads budget related to sales.

[Dataset](https://www.kaggle.com/harrimansaragih/dummy-advertising-and-sales-data) from Kaggle: https://www.kaggle.com/harrimansaragih/dummy-advertising-and-sales-data
